"""
Database-integrated similarity matcher using embeddings stored in PostgreSQL
"""
import numpy as np
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

from .config import SIMILARITY_THRESHOLDS
from .api_client import APIClient

# Note: Ensure api_client.py has these methods:
# - get_embeddings_by_corpus(corpus_id, type)
# - get_embeddings_by_paper(paper_id, type)
# - get_papers_by_corpus(corpus_id)
# These are already in your api_client.py


async def run_similarity_matching(
    api_client: APIClient,
    user_id: int,
    user_corpus_id: int,
    arxiv_corpus_id: int,
    threshold: str = "medium",
    method: str = "cosine",
    model_name: str = "all-MiniLM-L6-v2"
):
    """
    Compare user papers against arXiv papers using database-stored embeddings
    
    Args:
        api_client: API client instance
        user_id: Database user ID
        user_corpus_id: User's corpus ID
        arxiv_corpus_id: arXiv corpus ID
        threshold: Similarity threshold label
        method: Similarity method (cosine, faiss, qdrant)
        model_name: Embedding model name
    """
    threshold_value = SIMILARITY_THRESHOLDS.get(threshold, 0.6)
    
    print(f"\n▶ Running similarity matching (threshold={threshold}, method={method})")
    
    # Get embeddings
    user_embeddings = await api_client.get_embeddings_by_corpus(user_corpus_id, type="abstract")
    arxiv_embeddings = await api_client.get_embeddings_by_corpus(arxiv_corpus_id, type="abstract")
    
    print(f"✓ Loaded {len(user_embeddings)} user embeddings, {len(arxiv_embeddings)} arXiv embeddings")
    
    # Get user section embeddings
    user_papers = await api_client.get_papers_by_corpus(user_corpus_id)
    arxiv_papers = await api_client.get_papers_by_corpus(arxiv_corpus_id)
    
    # Create paper ID maps
    arxiv_paper_map = {p['id']: p for p in arxiv_papers}
    
    # Create recommendation run
    run = await api_client.create_recommendation_run(
        profile_id=None,  # Can be linked to a profile later
        user_id=user_id,
        user_corpus_id=user_corpus_id,
        ref_corpus_id=arxiv_corpus_id,
        threshold=threshold,
        method=method
    )
    
    print(f"✓ Created recommendation run ID: {run['id']}")
    
    # Compute similarities
    matches = []
    
    for arxiv_emb in arxiv_embeddings:
        arxiv_paper = arxiv_paper_map.get(arxiv_emb['paper_id'])
        if not arxiv_paper:
            continue
        
        arxiv_vec = np.array(arxiv_emb['embedding']).reshape(1, -1)
        max_score = 0.0
        
        # Compare against all user papers
        for user_emb in user_embeddings:
            user_vec = np.array(user_emb['embedding']).reshape(1, -1)
            
            if method == "cosine":
                score = cosine_similarity(user_vec, arxiv_vec)[0][0]
            else:
                # Fallback to cosine for now
                score = cosine_similarity(user_vec, arxiv_vec)[0][0]
            
            max_score = max(max_score, score)
        
        # Also compare sections if available
        section_score = await compare_sections(
            api_client,
            user_papers,
            arxiv_paper['id'],
            method
        )
        
        max_score = max(max_score, section_score)
        
        if max_score >= threshold_value:
            matches.append({
                'paper_id': arxiv_paper['id'],
                'score': float(max_score),
                'paper': arxiv_paper
            })
    
    # Sort by score
    matches.sort(key=lambda x: x['score'], reverse=True)
    
    # Store recommendations
    for rank, match in enumerate(matches[:50], 1):  # Top 50
        try:
            await api_client.create_recommendation(
                run_id=run['id'],
                paper_id=match['paper_id'],
                score=match['score'],
                rank=rank,
                summary=match['paper'].get('abstract', '')[:500]
            )
        except Exception as e:
            print(f"✗ Failed to store recommendation for paper {match['paper_id']}: {e}")
    
    print(f"✓ Stored {len(matches)} recommendations")
    
    # Print top matches
    print("\n=== Top Recommendations ===")
    for match in matches[:10]:
        paper = match['paper']
        print(f"\n[{match['score']:.3f}] {paper['title']}")
        print(f"  arXiv: {paper.get('arxiv_id', 'N/A')}")
    
    return matches


async def compare_sections(
    api_client: APIClient,
    user_papers: List[Dict],
    arxiv_paper_id: int,
    method: str = "cosine"
) -> float:
    """
    Compare section-level embeddings between user papers and arXiv paper
    
    Returns maximum similarity score across all section comparisons
    """
    max_score = 0.0
    
    # Get arXiv paper sections
    arxiv_section_embs = await api_client.get_embeddings_by_paper(
        arxiv_paper_id,
        type="section"
    )
    
    if not arxiv_section_embs:
        return 0.0
    
    # Compare against each user paper's sections
    for user_paper in user_papers:
        user_section_embs = await api_client.get_embeddings_by_paper(
            user_paper['id'],
            type="section"
        )
        
        if not user_section_embs:
            continue
        
        # Compare all section pairs
        for arxiv_sec in arxiv_section_embs:
            arxiv_vec = np.array(arxiv_sec['embedding']).reshape(1, -1)
            
            for user_sec in user_section_embs:
                user_vec = np.array(user_sec['embedding']).reshape(1, -1)
                
                if method == "cosine":
                    score = cosine_similarity(user_vec, arxiv_vec)[0][0]
                else:
                    score = cosine_similarity(user_vec, arxiv_vec)[0][0]
                
                max_score = max(max_score, score)
    
    return max_score