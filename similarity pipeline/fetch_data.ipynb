{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install feedparser sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74821b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cs.AI\n",
      "Fetching cs.AR\n",
      "Fetching cs.CC\n",
      "Fetching cs.CE\n",
      "Fetching cs.CG\n",
      "Fetching cs.CL\n",
      "Fetching cs.CR\n",
      "Fetching cs.CV\n",
      "Fetching cs.CY\n",
      "Fetching cs.DB\n",
      "Fetching cs.DC\n",
      "Fetching cs.DL\n",
      "Fetching cs.DM\n",
      "Fetching cs.DS\n",
      "Fetching cs.ET\n",
      "Fetching cs.FL\n",
      "Fetching cs.GL\n",
      "Fetching cs.GR\n",
      "Fetching cs.GT\n",
      "Fetching cs.HC\n",
      "Fetching cs.IR\n",
      "Fetching cs.IT\n",
      "Fetching cs.LG\n",
      "Fetching cs.LO\n",
      "Fetching cs.MA\n",
      "Fetching cs.MM\n",
      "Fetching cs.MS\n",
      "Fetching cs.NA\n",
      "Fetching cs.NE\n",
      "Fetching cs.NI\n",
      "Fetching cs.OH\n",
      "Fetching cs.OS\n",
      "Fetching cs.PF\n",
      "Fetching cs.PL\n",
      "Fetching cs.RO\n",
      "Fetching cs.SC\n",
      "Fetching cs.SD\n",
      "Fetching cs.SE\n",
      "Fetching cs.SI\n",
      "Fetching cs.SY\n",
      "Total papers fetched: 4000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "\n",
    "cs_categories = [\n",
    "    \"cs.AI\", \"cs.AR\", \"cs.CC\", \"cs.CE\", \"cs.CG\", \"cs.CL\", \"cs.CR\", \"cs.CV\",\n",
    "    \"cs.CY\", \"cs.DB\", \"cs.DC\", \"cs.DL\", \"cs.DM\", \"cs.DS\", \"cs.ET\", \"cs.FL\",\n",
    "    \"cs.GL\", \"cs.GR\", \"cs.GT\", \"cs.HC\", \"cs.IR\", \"cs.IT\", \"cs.LG\", \"cs.LO\",\n",
    "    \"cs.MA\", \"cs.MM\", \"cs.MS\", \"cs.NA\", \"cs.NE\", \"cs.NI\", \"cs.OH\", \"cs.OS\",\n",
    "    \"cs.PF\", \"cs.PL\", \"cs.RO\", \"cs.SC\", \"cs.SD\", \"cs.SE\", \"cs.SI\", \"cs.SY\"\n",
    "]\n",
    "\n",
    "def fetch_arxiv_papers(category, max_results=10):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    query = f\"search_query=cat:{category}&start=0&max_results={max_results}&sortBy=submittedDate&sortOrder=descending\"\n",
    "    response = requests.get(base_url + query)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {category}\")\n",
    "        return []\n",
    "    feed = feedparser.parse(response.content)\n",
    "    papers = []\n",
    "    for entry in feed.entries:\n",
    "        papers.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"title\": entry.title.strip(),\n",
    "            \"summary\": entry.summary.strip(),\n",
    "            \"published\": entry.published,\n",
    "            \"arxiv_url\": entry.link,\n",
    "            \"category\": category\n",
    "        })\n",
    "    return papers\n",
    "\n",
    "all_cs_papers =[]\n",
    "for cat in cs_categories:\n",
    "    print(f\"Fetching {cat}\")\n",
    "    all_cs_papers.extend(fetch_arxiv_papers(cat, max_results=100))\n",
    "\n",
    "with open(\"arxiv_cs_papers.json\",\"w\") as f:\n",
    "    json.dump(all_cs_papers, f, indent=2)\n",
    "\n",
    "print(f\"Total papers fetched: {len(all_cs_papers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77561feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def embed_texts(texts, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model.encode(texts, convert_to_tensor=False, normalize_embeddings=False)\n",
    "\n",
    "with open(\"arxiv_cs_papers.json\", \"r\") as f:\n",
    "    new_papers = json.load(f)\n",
    "\n",
    "new_summaries = [paper[\"summary\"] for paper in new_papers]\n",
    "new_embeddings = embed_texts(new_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6fdd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_corpus = [\n",
    "  {\n",
    "    \"id\": \"8a9258ed-dcc6-4c5f-a76e-ef4411a1dce5\",\n",
    "    \"title\": \"VerifyBench: Benchmarking Reference-based Reward Systems for Large\\n  Language Models\",\n",
    "    \"summary\": \"Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved\\nremarkable performance in the domain of reasoning. A key component of their\\ntraining is the incorporation of verifiable rewards within reinforcement\\nlearning (RL). However, existing reward benchmarks do not evaluate\\nreference-based reward systems, leaving researchers with limited understanding\\nof the accuracy of verifiers used in RL. In this paper, we introduce two\\nbenchmarks, VerifyBench and VerifyBench-Hard, designed to assess the\\nperformance of reference-based reward systems. These benchmarks are constructed\\nthrough meticulous data collection and curation, followed by careful human\\nannotation to ensure high quality. Current models still show considerable room\\nfor improvement on both VerifyBench and VerifyBench-Hard, especially\\nsmaller-scale models. Furthermore, we conduct a thorough and comprehensive\\nanalysis of evaluation results, offering insights for understanding and\\ndeveloping reference-based reward systems. Our proposed benchmarks serve as\\neffective tools for guiding the development of verifier accuracy and the\\nreasoning capabilities of models trained via RL in reasoning tasks.\",\n",
    "    \"published\": \"2025-05-21T17:54:43Z\",\n",
    "    \"arxiv_url\": \"http://arxiv.org/abs/2505.15801v1\",\n",
    "    \"category\": \"cs.AI\"\n",
    "  },\n",
    "]\n",
    "\n",
    "user_summaries = [doc[\"summary\"] for doc in user_corpus]\n",
    "user_embeddings = embed_texts(user_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4169b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 relevant new papers\n",
      "VerifyBench: Benchmarking Reference-based Reward Systems for Large\n",
      "  Language Models (1.00)\n",
      "http://arxiv.org/abs/2505.15801v1 \n",
      "\n",
      "VerifyBench: Benchmarking Reference-based Reward Systems for Large\n",
      "  Language Models (1.00)\n",
      "http://arxiv.org/abs/2505.15801v1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rank_by_similarity(new_papers, new_embeddings, user_embeddings, threshold=0.7):\n",
    "    sim_matrix = cosine_similarity(new_embeddings, user_embeddings)\n",
    "    max_scores = sim_matrix.max(axis=1)\n",
    "    ranked = [\n",
    "        {\n",
    "            \"title\": new_papers[i]['title'],\n",
    "            \"summary\": new_papers[i]['summary'],\n",
    "            \"url\": new_papers[i]['arxiv_url'],\n",
    "            \"published\": new_papers[i]['published'],\n",
    "            \"score\": float(max_scores[i])\n",
    "        }\n",
    "        for i in range(len(new_papers)) if max_scores[i] >= threshold\n",
    "    ]\n",
    "    return sorted(ranked, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "ranked_matches = rank_by_similarity(new_papers, new_embeddings, user_embeddings)\n",
    "\n",
    "with open(\"ranked_matches.json\",\"w\") as f:\n",
    "    json.dump(ranked_matches, f, indent=2)\n",
    "\n",
    "print(f\"Found {len(ranked_matches)} relevant new papers\")\n",
    "for match in ranked_matches[:5]:\n",
    "    print(f\"{match['title']} ({match['score']:.2f})\")\n",
    "    print(match['url'], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
